{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "715b4491",
   "metadata": {},
   "source": [
    "# Chain\n",
    "\n",
    "Review - We built a simple graph with nodes, normal edges and conditional edges.\n",
    "\n",
    "Goals Now, let's build up to a simple chain that combines 4 concepts:\n",
    "\n",
    "Using chat messages as our graph state Using chat models in graph nodes Binding tools to our chat model Executing tool calls in graph nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d908b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "So you said you were researching ocean mammals?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "Yes, that's right.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Name: Model\n",
      "\n",
      "Great, what would you like to learn about.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: Lance\n",
      "\n",
      "I want to learn about the best place to see Orcas in the US.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "messages = [AIMessage(content=f\"So you said you were researching ocean mammals?\", name=\"Model\")]\n",
    "messages.append(HumanMessage(content=f\"Yes, that's right.\", name=\"Lance\"))\n",
    "messages.append(AIMessage(content=f\"Great, what would you like to learn about.\", name=\"Model\"))\n",
    "messages.append(HumanMessage(content=f\"I want to learn about the best place to see Orcas in the US.\", name=\"Lance\"))\n",
    "\n",
    "for m in messages:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a01aa5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c03da98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's a fantastic choice! Orcas, also known as killer whales, are truly magnificent creatures.  \\n\\nThe best place to see orcas in the US is widely considered to be **the Pacific Northwest, specifically around Washington State**. \\n\\nHere's why:\\n\\n* **Resident Orca Populations:** The Salish Sea, which encompasses the waters surrounding Washington state, is home to three distinct resident orca populations: \\n    *  **J Pod:**  The most famous, known for being very active and often seen near the San Juan Islands.\\n    * **K Pod:**  Also frequently sighted in the San Juan Islands.\\n    * **L Pod:**  Often found near the Olympic Peninsula.\\n* **Whale Watching Tours:**  Numerous reputable whale watching tours operate from various locations in the San Juan Islands, including Friday Harbor, Anacortes, and Port Townsend. These tours offer a high chance of spotting orcas and provide knowledgeable guides who can share fascinating information.\\n* **Abundant Food Sources:** The Salish Sea is rich in salmon and other prey species that attract orcas. \\n* **Ideal Viewing Conditions:**  The San Juan Islands offer clear waters, calm seas, and stunning scenery, making for unforgettable whale watching experiences.\\n\\n**Here are some additional tips for seeing orcas:**\\n\\n* **Go during the right season:** While orcas can be seen year-round, the best time to spot them is from May to October.\\n* **Book your tour in advance:** Whale watching tours are in high demand, especially during peak season.\\n* **Be patient:**  Whale sightings are not guaranteed, but with a little luck and patience, you'll likely have a memorable encounter.\\n\\n\\n\\nLet me know if you have any other questions about seeing orcas in the US!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 373, 'prompt_tokens': 71, 'total_tokens': 444, 'completion_time': 0.678181818, 'prompt_time': 0.003838592, 'queue_time': 0.23420665699999998, 'total_time': 0.68202041}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-9ca67bdd-2872-4538-8c7a-249d53b72462-0', usage_metadata={'input_tokens': 71, 'output_tokens': 373, 'total_tokens': 444})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm=ChatGroq(model=\"gemma2-9b-it\")\n",
    "result=llm.invoke(messages)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46400e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(a:int, b:int)-> int:\n",
    "    \"\"\"\n",
    "    Add a and b.\n",
    "    \n",
    "    Args:\n",
    "        a: first int\n",
    "        b: second int\n",
    "    \"\"\"\n",
    "    return a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81f0ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools=llm.bind_tools([add])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b360473d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_k3y2', 'function': {'arguments': '{\"a\":2,\"b\":3}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 982, 'total_tokens': 1068, 'completion_time': 0.156363636, 'prompt_time': 0.034402189, 'queue_time': 0.23649851600000002, 'total_time': 0.190765825}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-9cb1bf22-dbb8-4d02-83e9-6dc9f1547f3a-0', tool_calls=[{'name': 'add', 'args': {'a': 2, 'b': 3}, 'id': 'call_k3y2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 982, 'output_tokens': 86, 'total_tokens': 1068})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call=llm_with_tools.invoke([HumanMessage(content=f\"What is 2 plus 3\", name=\"Lance\")])\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be1e14bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'a': 2, 'b': 3},\n",
       "  'id': 'call_k3y2',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "070a59df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class MessageState(TypedDict):\n",
    "    messages:Annotated[list[AnyMessage], add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2531d065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}, name='Model', id='7f011627-4af7-4faf-8d21-81b5aeae6e71'),\n",
       " HumanMessage(content=\"I'm looking for information on generative ai.\", additional_kwargs={}, response_metadata={}, name='Deepak', id='d5f70da4-1d2b-4d1e-b96c-6aebdc203f1e'),\n",
       " AIMessage(content='Sure, I can help with that. What specific are you interested in?', additional_kwargs={}, response_metadata={}, name='Model', id='ad793935-b3b2-4a60-a022-e0a2e1d82ec1')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_message=[AIMessage(content=\"Hello! How can I assist you?\", name=\"Model\"),\n",
    "                HumanMessage(content=\"I'm looking for information on generative ai.\", name=\"Deepak\")\n",
    "                ]\n",
    "#New message to add\n",
    "new_message= AIMessage(content=\"Sure, I can help with that. What specific are you interested in?\", name=\"Model\")\n",
    "add_messages(initial_message, new_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d247c0ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
